{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b4e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(0)\n",
    "\n",
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11776d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch >= 2:\n",
    "        lr = 2e-5\n",
    "    else:\n",
    "        lr = 1e-6\n",
    "        \n",
    "    lr *= 4\n",
    "\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    optimizer.param_groups[1]['lr'] = 100*lr\n",
    "    \n",
    "    return lr\n",
    "\n",
    "\n",
    "def get_optimizer(net):\n",
    "    params = [x[1] for x in filter(lambda kv: \"backbone\" in kv[0], net.named_parameters())]\n",
    "    arc_weight = [x[1] for x in filter(lambda kv: \"backbone\" not in kv[0], net.named_parameters())]\n",
    "\n",
    "    optimizer = torch.optim.Adam([{\"params\": params}, {\"params\": arc_weight}], lr=3e-4, betas=(0.9, 0.999),\n",
    "                                 eps=1e-08)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357e6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.ls_eps = ls_eps\n",
    "        self.arc_weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.arc_weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.set_margin(margin)\n",
    "        \n",
    "    def set_margin(self, margin):\n",
    "        self.margin = margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        \n",
    "        self.th = nn.Parameter(torch.FloatTensor([math.cos(math.pi - margin)]), requires_grad=False)\n",
    "        self.mm = nn.Parameter(torch.FloatTensor([math.sin(math.pi - margin) * margin]), requires_grad=False)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.arc_weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = label #torch.zeros(cosine.size(), device='cuda')\n",
    "        #one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fa5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "\n",
    "\n",
    "class TrainingModel(nn.Module):\n",
    "    def __init__(self, model, num_classes):\n",
    "        super(TrainingModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.arcface = ArcMarginProduct(1024, num_classes, scale=20.0, margin=0.1)\n",
    "\n",
    "    def forward(self, ids, mask, label):\n",
    "        x = self.model(ids, mask)\n",
    "        return self.arcface(x, label)\n",
    "\n",
    "    \n",
    "class VecModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(VecModel, self).__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        print(self.backbone)\n",
    "        self.bn = nn.BatchNorm1d(1024)\n",
    "        self.top = nn.Linear(1024, 1024)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        out = self.backbone(ids, mask)[0]\n",
    "        out = (out[:, 1:MAX_LEN//2, :]*mask[:, 1:MAX_LEN//2, None]).mean(axis=1)\n",
    "        \n",
    "        return F.normalize(self.top(self.bn(out)))\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2207e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279914</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>c_d64037a72376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279915</th>\n",
       "      <td>t_fffbe1d5d43c</td>\n",
       "      <td>c_46f852a49c08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279916</th>\n",
       "      <td>t_fffbe1d5d43c</td>\n",
       "      <td>c_6659207b25d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279917</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_cece166bad6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279918</th>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>c_92b8fad372ee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              topic_id     content_ids\n",
       "0       t_00004da3a1b2  c_1108dd0c7a5d\n",
       "1       t_00004da3a1b2  c_376c5a8eb028\n",
       "2       t_00004da3a1b2  c_5bc0e1e2cba0\n",
       "3       t_00004da3a1b2  c_76231f9d0b5e\n",
       "4       t_00068291e9a4  c_639ea2ef9c95\n",
       "...                ...             ...\n",
       "279914  t_fff9e5407d13  c_d64037a72376\n",
       "279915  t_fffbe1d5d43c  c_46f852a49c08\n",
       "279916  t_fffbe1d5d43c  c_6659207b25d5\n",
       "279917  t_fffe14f1be1e  c_cece166bad6a\n",
       "279918  t_fffe811a6da9  c_92b8fad372ee\n",
       "\n",
       "[279919 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = pd.read_csv(\"data/correlations.csv\")\n",
    "\n",
    "corr_df[\"content_ids\"] = corr_df[\"content_ids\"].apply(lambda x: x.split())\n",
    "\n",
    "corr_df = corr_df.explode('content_ids').reset_index(drop=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d6939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61517, 9)\n",
      "(61517, 10)\n",
      "(61517, 12)\n",
      "(61517, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>level</th>\n",
       "      <th>language</th>\n",
       "      <th>parent</th>\n",
       "      <th>has_content</th>\n",
       "      <th>parent_title</th>\n",
       "      <th>grandpa</th>\n",
       "      <th>grandpa_title</th>\n",
       "      <th>ggrandpa</th>\n",
       "      <th>ggrandpa_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>Откриването на резисторите @ Открития и проект...</td>\n",
       "      <td>Изследване на материали, които предизвикват на...</td>\n",
       "      <td>000cf7</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>bg</td>\n",
       "      <td>t_16e29365b50d</td>\n",
       "      <td>True</td>\n",
       "      <td>Открития и проекти</td>\n",
       "      <td>t_c85886762db7</td>\n",
       "      <td>Физика</td>\n",
       "      <td>t_27a0a3c7ee9a</td>\n",
       "      <td>Наука</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>Entradas e saídas de uma função @ Álgebra: fun...</td>\n",
       "      <td>Entenda um pouco mais sobre funções.</td>\n",
       "      <td>8e286a</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>pt</td>\n",
       "      <td>t_d14b6c2a2b70</td>\n",
       "      <td>True</td>\n",
       "      <td>Álgebra: funções</td>\n",
       "      <td>t_461c9a8dd863</td>\n",
       "      <td>9º Ano</td>\n",
       "      <td>t_a6420bcff569</td>\n",
       "      <td>Matemática por ano (Alinhada à BNCC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>Transcripts @ Flow Charts: Logical Thinking? @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6e3ba4</td>\n",
       "      <td>source</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>True</td>\n",
       "      <td>Flow Charts: Logical Thinking?</td>\n",
       "      <td>t_acbbd893e6af</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>t_9c5f09334d83</td>\n",
       "      <td>MIT Blossoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "      <td>Научи повече за графиките на сложните показате...</td>\n",
       "      <td>000cf7</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>bg</td>\n",
       "      <td>t_e2452e21d252</td>\n",
       "      <td>True</td>\n",
       "      <td>Показателни и логаритмични функции</td>\n",
       "      <td>t_5f4cc8e02423</td>\n",
       "      <td>Алгебра (цялото съдържание)</td>\n",
       "      <td>t_afd8db5e4f44</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0008768bdee6</td>\n",
       "      <td>100 સુધીનો સરવાળો @ 100 સુધીના સરવાળા અને બાદબ...</td>\n",
       "      <td>37 અને 49 જેવી બે-અંકની સંખ્યાઓ ઉમેરતા શીખો.</td>\n",
       "      <td>5223e0</td>\n",
       "      <td>supplemental</td>\n",
       "      <td>4</td>\n",
       "      <td>gu</td>\n",
       "      <td>t_0da7a331d666</td>\n",
       "      <td>True</td>\n",
       "      <td>100 સુધીના સરવાળા અને બાદબાકી</td>\n",
       "      <td>t_d20fc01fdf38</td>\n",
       "      <td>પ્રારંભિક ગણિત</td>\n",
       "      <td>t_38bca5075c51</td>\n",
       "      <td>ધોરણ ૩</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "0  t_00004da3a1b2  Откриването на резисторите @ Открития и проект...   \n",
       "1  t_00068291e9a4  Entradas e saídas de uma função @ Álgebra: fun...   \n",
       "2  t_00069b63a70a  Transcripts @ Flow Charts: Logical Thinking? @...   \n",
       "3  t_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...   \n",
       "4  t_0008768bdee6  100 સુધીનો સરવાળો @ 100 સુધીના સરવાળા અને બાદબ...   \n",
       "\n",
       "                                         description channel      category  \\\n",
       "0  Изследване на материали, които предизвикват на...  000cf7        source   \n",
       "1               Entenda um pouco mais sobre funções.  8e286a        source   \n",
       "2                                                NaN  6e3ba4        source   \n",
       "3  Научи повече за графиките на сложните показате...  000cf7        source   \n",
       "4       37 અને 49 જેવી બે-અંકની સંખ્યાઓ ઉમેરતા શીખો.  5223e0  supplemental   \n",
       "\n",
       "   level language          parent  has_content  \\\n",
       "0      4       bg  t_16e29365b50d         True   \n",
       "1      4       pt  t_d14b6c2a2b70         True   \n",
       "2      3       en  t_4054df11a74e         True   \n",
       "3      4       bg  t_e2452e21d252         True   \n",
       "4      4       gu  t_0da7a331d666         True   \n",
       "\n",
       "                         parent_title         grandpa  \\\n",
       "0                  Открития и проекти  t_c85886762db7   \n",
       "1                    Álgebra: funções  t_461c9a8dd863   \n",
       "2      Flow Charts: Logical Thinking?  t_acbbd893e6af   \n",
       "3  Показателни и логаритмични функции  t_5f4cc8e02423   \n",
       "4       100 સુધીના સરવાળા અને બાદબાકી  t_d20fc01fdf38   \n",
       "\n",
       "                 grandpa_title        ggrandpa  \\\n",
       "0                       Физика  t_27a0a3c7ee9a   \n",
       "1                       9º Ano  t_a6420bcff569   \n",
       "2                  Engineering  t_9c5f09334d83   \n",
       "3  Алгебра (цялото съдържание)  t_afd8db5e4f44   \n",
       "4               પ્રારંભિક ગણિત  t_38bca5075c51   \n",
       "\n",
       "                         ggrandpa_title  \n",
       "0                                 Наука  \n",
       "1  Matemática por ano (Alinhada à BNCC)  \n",
       "2                          MIT Blossoms  \n",
       "3                            Математика  \n",
       "4                                ધોરણ ૩  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df = pd.read_csv(\"data/topics.csv\")\n",
    "topic_df[\"title\"] = topic_df[\"title\"].fillna(\"\")\n",
    "\n",
    "title_map = topic_df.set_index(\"id\")[\"title\"].to_dict()\n",
    "parent_map = topic_df.set_index(\"id\")[\"parent\"].to_dict()\n",
    "\n",
    "topic_df = topic_df[topic_df[\"has_content\"]].reset_index(drop=True)\n",
    "print(topic_df.shape)\n",
    "\n",
    "topic_df[\"parent_title\"] = topic_df[\"parent\"].apply(lambda x: title_map.get(x, \"\"))\n",
    "print(topic_df.shape)\n",
    "\n",
    "topic_df[\"grandpa\"] = topic_df[\"parent\"].apply(lambda x: parent_map.get(x))\n",
    "topic_df[\"grandpa_title\"] = topic_df[\"grandpa\"].apply(lambda x: title_map.get(x, \"\"))\n",
    "print(topic_df.shape)\n",
    "\n",
    "topic_df[\"ggrandpa\"] = topic_df[\"grandpa\"].apply(lambda x: parent_map.get(x))\n",
    "topic_df[\"ggrandpa_title\"] = topic_df[\"ggrandpa\"].apply(lambda x: title_map.get(x, \"\"))\n",
    "print(topic_df.shape)\n",
    "\n",
    "topic_df[\"title\"] = topic_df[\"title\"] + \" @ \" + topic_df[\"parent_title\"] + \" @ \" + topic_df[\"grandpa_title\"] + \" @ \" + topic_df[\"ggrandpa_title\"]\n",
    "\n",
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb133c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20506\n",
       "1    20506\n",
       "2    20505\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "N_FOLDS = 3\n",
    "\n",
    "splits = KFold(N_FOLDS, shuffle=True, random_state=0).split(topic_df, topic_df[\"has_content\"])\n",
    "\n",
    "topic_df[\"fold\"] = 0\n",
    "\n",
    "for f, (train_ind, val_ind) in enumerate(splits):\n",
    "    topic_df.loc[val_ind, \"fold\"] = f\n",
    "\n",
    "topic_df[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a458bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    53269\n",
       "0     8248\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.loc[(topic_df[\"category\"] == \"source\") | (topic_df[\"fold\"] > 0), \"fold\"] = 1\n",
    "topic_df[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8477884",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_topic = LabelEncoder()\n",
    "topic_df[\"t\"] = topic_df[\"title\"].fillna(\"\") + \" | \" + topic_df[\"description\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6590e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50096, 17), (8248, 17))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_FOLD = 0\n",
    "\n",
    "topic_df  = topic_df[topic_df[\"language\"] != \"ar\"]\n",
    "\n",
    "topic_df[\"sw\"] = 1\n",
    "\n",
    "topic_df_test = topic_df[topic_df[\"fold\"] == TEST_FOLD].reset_index(drop=True)\n",
    "topic_df_train = topic_df[topic_df[\"fold\"] != TEST_FOLD].reset_index(drop=True)\n",
    "\n",
    "\n",
    "topic_df_train.shape, topic_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522f61d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146629, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>kind</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>copyright_holder</th>\n",
       "      <th>license</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_00002381196d</td>\n",
       "      <td>Sumar números de varios dígitos: 48,029+233,930</td>\n",
       "      <td>Suma 48,029+233,930 mediante el algoritmo está...</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumar números de varios dígitos: 48,029+233,93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_000087304a9e</td>\n",
       "      <td>Trovare i fattori di un numero</td>\n",
       "      <td>Sal trova i fattori di 120.\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trovare i fattori di un numero | video | Sal t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_0000ad142ddb</td>\n",
       "      <td>Sumar curvas de demanda</td>\n",
       "      <td>Cómo añadir curvas de demanda\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumar curvas de demanda | video | Cómo añadir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_0000c03adc8d</td>\n",
       "      <td>Nado de aproximação</td>\n",
       "      <td>Neste vídeo você vai aprender o nado de aproxi...</td>\n",
       "      <td>document</td>\n",
       "      <td>\\nNado de aproximação\\nSaber nadar nas ondas ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>Sikana Education</td>\n",
       "      <td>CC BY-NC-ND</td>\n",
       "      <td>Nado de aproximação | document | Neste vídeo v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_00016694ea2a</td>\n",
       "      <td>geometry-m3-topic-a-overview.pdf</td>\n",
       "      <td>Estándares Comunes del Estado de Nueva York\\n\\...</td>\n",
       "      <td>document</td>\n",
       "      <td>Estándares Comunes del Estado de Nueva York\\n\\...</td>\n",
       "      <td>es</td>\n",
       "      <td>Engage NY</td>\n",
       "      <td>CC BY-NC-SA</td>\n",
       "      <td>geometry-m3-topic-a-overview.pdf | document | ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                             title  \\\n",
       "0  c_00002381196d  Sumar números de varios dígitos: 48,029+233,930    \n",
       "1  c_000087304a9e                    Trovare i fattori di un numero   \n",
       "2  c_0000ad142ddb                           Sumar curvas de demanda   \n",
       "3  c_0000c03adc8d                               Nado de aproximação   \n",
       "4  c_00016694ea2a                  geometry-m3-topic-a-overview.pdf   \n",
       "\n",
       "                                         description      kind  \\\n",
       "0  Suma 48,029+233,930 mediante el algoritmo está...     video   \n",
       "1                    Sal trova i fattori di 120.\\n\\n     video   \n",
       "2                  Cómo añadir curvas de demanda\\n\\n     video   \n",
       "3  Neste vídeo você vai aprender o nado de aproxi...  document   \n",
       "4  Estándares Comunes del Estado de Nueva York\\n\\...  document   \n",
       "\n",
       "                                                text language  \\\n",
       "0                                                NaN       es   \n",
       "1                                                NaN       it   \n",
       "2                                                NaN       es   \n",
       "3  \\nNado de aproximação\\nSaber nadar nas ondas ...       pt   \n",
       "4  Estándares Comunes del Estado de Nueva York\\n\\...       es   \n",
       "\n",
       "   copyright_holder      license  \\\n",
       "0               NaN          NaN   \n",
       "1               NaN          NaN   \n",
       "2               NaN          NaN   \n",
       "3  Sikana Education  CC BY-NC-ND   \n",
       "4         Engage NY  CC BY-NC-SA   \n",
       "\n",
       "                                                   t  \n",
       "0  Sumar números de varios dígitos: 48,029+233,93...  \n",
       "1  Trovare i fattori di un numero | video | Sal t...  \n",
       "2  Sumar curvas de demanda | video | Cómo añadir ...  \n",
       "3  Nado de aproximação | document | Neste vídeo v...  \n",
       "4  geometry-m3-topic-a-overview.pdf | document | ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df = pd.read_csv(\"data/content.csv\")\n",
    "\n",
    "content_df  = content_df[content_df[\"language\"] != \"ar\"]\n",
    "\n",
    "content_df.loc[content_df[\"title\"] == content_df[\"description\"], \"description\"] = None\n",
    "content_df[\"description\"].fillna(content_df[\"text\"].fillna(\"\").apply(lambda x: x[:256]), inplace=True)\n",
    "content_df[\"t\"] = content_df[\"title\"].fillna(\"\") + \" | \" + content_df[\"kind\"].fillna(\"\") + \" | \" + content_df[\"description\"].fillna(\"\")\n",
    "\n",
    "print(content_df.shape)\n",
    "content_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1b4b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133704, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contents = corr_df.merge(topic_df_train[[\"id\"]], left_on=\"topic_id\", right_on=\"id\")\n",
    "train_contents[\"sw\"] = 1\n",
    "train_contents[\"sw\"] /= np.sqrt(train_contents.groupby(\"topic_id\")[\"id\"].transform(\"count\"))\n",
    "\n",
    "train_contents = train_contents.groupby(\"content_ids\")[\"sw\"].sum().reset_index()\n",
    "train_contents[\"sw\"] = train_contents[\"sw\"].clip(0.1, 10)\n",
    "\n",
    "train_contents.rename(columns={\"content_ids\": \"id\"}, inplace=True)\n",
    "train_contents[\"is_train\"] = True\n",
    "train_contents[\"sw\"] = train_contents.shape[0]*train_contents[\"sw\"]/train_contents[\"sw\"].sum()\n",
    "\n",
    "train_contents[\"sw\"] = 1\n",
    "train_contents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3745f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115250052854483"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df = content_df.merge(train_contents, on=\"id\", how=\"left\")\n",
    "content_df[\"is_train\"].fillna(False, inplace=True)\n",
    "content_df[\"sw\"].fillna(1.0, inplace=True)\n",
    "\n",
    "content_df[\"is_train\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe22c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df[\"label\"] = 0\n",
    "content_df.loc[content_df[\"is_train\"], \"label\"] = le_topic.fit_transform(content_df.loc[content_df[\"is_train\"], \"t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be1c7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>level</th>\n",
       "      <th>language</th>\n",
       "      <th>parent</th>\n",
       "      <th>has_content</th>\n",
       "      <th>parent_title</th>\n",
       "      <th>grandpa</th>\n",
       "      <th>grandpa_title</th>\n",
       "      <th>ggrandpa</th>\n",
       "      <th>ggrandpa_title</th>\n",
       "      <th>fold</th>\n",
       "      <th>t</th>\n",
       "      <th>sw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>Откриването на резисторите @ Открития и проект...</td>\n",
       "      <td>Изследване на материали, които предизвикват на...</td>\n",
       "      <td>000cf7</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>bg</td>\n",
       "      <td>t_16e29365b50d</td>\n",
       "      <td>True</td>\n",
       "      <td>Открития и проекти</td>\n",
       "      <td>t_c85886762db7</td>\n",
       "      <td>Физика</td>\n",
       "      <td>t_27a0a3c7ee9a</td>\n",
       "      <td>Наука</td>\n",
       "      <td>1</td>\n",
       "      <td>Откриването на резисторите @ Открития и проект...</td>\n",
       "      <td>1</td>\n",
       "      <td>[111544, 113249, 114120, 114624]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>Entradas e saídas de uma função @ Álgebra: fun...</td>\n",
       "      <td>Entenda um pouco mais sobre funções.</td>\n",
       "      <td>8e286a</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>pt</td>\n",
       "      <td>t_d14b6c2a2b70</td>\n",
       "      <td>True</td>\n",
       "      <td>Álgebra: funções</td>\n",
       "      <td>t_461c9a8dd863</td>\n",
       "      <td>9º Ano</td>\n",
       "      <td>t_a6420bcff569</td>\n",
       "      <td>Matemática por ano (Alinhada à BNCC)</td>\n",
       "      <td>1</td>\n",
       "      <td>Entradas e saídas de uma função @ Álgebra: fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>[89691, 35260, 35259, 89692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>Transcripts @ Flow Charts: Logical Thinking? @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6e3ba4</td>\n",
       "      <td>source</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>True</td>\n",
       "      <td>Flow Charts: Logical Thinking?</td>\n",
       "      <td>t_acbbd893e6af</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>t_9c5f09334d83</td>\n",
       "      <td>MIT Blossoms</td>\n",
       "      <td>1</td>\n",
       "      <td>Transcripts @ Flow Charts: Logical Thinking? @...</td>\n",
       "      <td>1</td>\n",
       "      <td>[48571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "      <td>Научи повече за графиките на сложните показате...</td>\n",
       "      <td>000cf7</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>bg</td>\n",
       "      <td>t_e2452e21d252</td>\n",
       "      <td>True</td>\n",
       "      <td>Показателни и логаритмични функции</td>\n",
       "      <td>t_5f4cc8e02423</td>\n",
       "      <td>Алгебра (цялото съдържание)</td>\n",
       "      <td>t_afd8db5e4f44</td>\n",
       "      <td>Математика</td>\n",
       "      <td>1</td>\n",
       "      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n",
       "      <td>1</td>\n",
       "      <td>[111488, 116870, 111475, 116276, 116277]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0008768bdee6</td>\n",
       "      <td>100 સુધીનો સરવાળો @ 100 સુધીના સરવાળા અને બાદબ...</td>\n",
       "      <td>37 અને 49 જેવી બે-અંકની સંખ્યાઓ ઉમેરતા શીખો.</td>\n",
       "      <td>5223e0</td>\n",
       "      <td>supplemental</td>\n",
       "      <td>4</td>\n",
       "      <td>gu</td>\n",
       "      <td>t_0da7a331d666</td>\n",
       "      <td>True</td>\n",
       "      <td>100 સુધીના સરવાળા અને બાદબાકી</td>\n",
       "      <td>t_d20fc01fdf38</td>\n",
       "      <td>પ્રારંભિક ગણિત</td>\n",
       "      <td>t_38bca5075c51</td>\n",
       "      <td>ધોરણ ૩</td>\n",
       "      <td>1</td>\n",
       "      <td>100 સુધીનો સરવાળો @ 100 સુધીના સરવાળા અને બાદબ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[126376, 126369, 126548]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50091</th>\n",
       "      <td>t_fff7f2dd208b</td>\n",
       "      <td>Fatoração de polinômios encontrando fatores co...</td>\n",
       "      <td>Aprenda a fatorar utilizando fatores comuns.</td>\n",
       "      <td>8e286a</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>pt</td>\n",
       "      <td>t_28dfc9e80110</td>\n",
       "      <td>True</td>\n",
       "      <td>Álgebra: expressões algébricas</td>\n",
       "      <td>t_461c9a8dd863</td>\n",
       "      <td>9º Ano</td>\n",
       "      <td>t_a6420bcff569</td>\n",
       "      <td>Matemática por ano (Alinhada à BNCC)</td>\n",
       "      <td>1</td>\n",
       "      <td>Fatoração de polinômios encontrando fatores co...</td>\n",
       "      <td>1</td>\n",
       "      <td>[47584, 47552, 34508, 34509, 34510, 47572]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50092</th>\n",
       "      <td>t_fff830472691</td>\n",
       "      <td>Scalar Projections @ Vector Analysis @ Analysi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fef095</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>t_c75d6acecf78</td>\n",
       "      <td>True</td>\n",
       "      <td>Vector Analysis</td>\n",
       "      <td>t_de58fdbcad60</td>\n",
       "      <td>Analysis</td>\n",
       "      <td>t_9d8388491acd</td>\n",
       "      <td>Math</td>\n",
       "      <td>1</td>\n",
       "      <td>Scalar Projections @ Vector Analysis @ Analysi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[91761, 91762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50093</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>NA_U06 - El periódico @ Lengua española @ PF (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71fd51</td>\n",
       "      <td>supplemental</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "      <td>t_5bd8f6ae9f7d</td>\n",
       "      <td>True</td>\n",
       "      <td>Lengua española</td>\n",
       "      <td>t_3eca90fe0fe1</td>\n",
       "      <td>PF (Español)</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>NA_U06 - El periódico @ Lengua española @ PF (...</td>\n",
       "      <td>1</td>\n",
       "      <td>[22630, 41353, 82122, 63443, 41684, 62933, 640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50094</th>\n",
       "      <td>t_fffbe1d5d43c</td>\n",
       "      <td>Inscribed shapes problem solving @ Miduara @ C...</td>\n",
       "      <td>Use properties of inscribed angles to prove pr...</td>\n",
       "      <td>0c929f</td>\n",
       "      <td>source</td>\n",
       "      <td>4</td>\n",
       "      <td>sw</td>\n",
       "      <td>t_50145b9bab3f</td>\n",
       "      <td>True</td>\n",
       "      <td>Miduara</td>\n",
       "      <td>t_c520677cef1d</td>\n",
       "      <td>Class 9 (India)</td>\n",
       "      <td>t_4853606228df</td>\n",
       "      <td>Hisabati</td>\n",
       "      <td>1</td>\n",
       "      <td>Inscribed shapes problem solving @ Miduara @ C...</td>\n",
       "      <td>1</td>\n",
       "      <td>[18867, 85597]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50095</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>Lección 7 @ Unidad 4 @ Español Actividades 1ro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6e90a7</td>\n",
       "      <td>aligned</td>\n",
       "      <td>6</td>\n",
       "      <td>es</td>\n",
       "      <td>t_d448c707984d</td>\n",
       "      <td>True</td>\n",
       "      <td>Unidad 4</td>\n",
       "      <td>t_8c734f803ed6</td>\n",
       "      <td>Español Actividades 1ro</td>\n",
       "      <td>t_7eb0dc459971</td>\n",
       "      <td>01 Primero</td>\n",
       "      <td>1</td>\n",
       "      <td>Lección 7 @ Unidad 4 @ Español Actividades 1ro...</td>\n",
       "      <td>1</td>\n",
       "      <td>[61581]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50096 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              title  \\\n",
       "0      t_00004da3a1b2  Откриването на резисторите @ Открития и проект...   \n",
       "1      t_00068291e9a4  Entradas e saídas de uma função @ Álgebra: fun...   \n",
       "2      t_00069b63a70a  Transcripts @ Flow Charts: Logical Thinking? @...   \n",
       "3      t_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...   \n",
       "4      t_0008768bdee6  100 સુધીનો સરવાળો @ 100 સુધીના સરવાળા અને બાદબ...   \n",
       "...               ...                                                ...   \n",
       "50091  t_fff7f2dd208b  Fatoração de polinômios encontrando fatores co...   \n",
       "50092  t_fff830472691  Scalar Projections @ Vector Analysis @ Analysi...   \n",
       "50093  t_fff9e5407d13  NA_U06 - El periódico @ Lengua española @ PF (...   \n",
       "50094  t_fffbe1d5d43c  Inscribed shapes problem solving @ Miduara @ C...   \n",
       "50095  t_fffe14f1be1e  Lección 7 @ Unidad 4 @ Español Actividades 1ro...   \n",
       "\n",
       "                                             description channel  \\\n",
       "0      Изследване на материали, които предизвикват на...  000cf7   \n",
       "1                   Entenda um pouco mais sobre funções.  8e286a   \n",
       "2                                                    NaN  6e3ba4   \n",
       "3      Научи повече за графиките на сложните показате...  000cf7   \n",
       "4           37 અને 49 જેવી બે-અંકની સંખ્યાઓ ઉમેરતા શીખો.  5223e0   \n",
       "...                                                  ...     ...   \n",
       "50091       Aprenda a fatorar utilizando fatores comuns.  8e286a   \n",
       "50092                                                NaN  fef095   \n",
       "50093                                                NaN  71fd51   \n",
       "50094  Use properties of inscribed angles to prove pr...  0c929f   \n",
       "50095                                                NaN  6e90a7   \n",
       "\n",
       "           category  level language          parent  has_content  \\\n",
       "0            source      4       bg  t_16e29365b50d         True   \n",
       "1            source      4       pt  t_d14b6c2a2b70         True   \n",
       "2            source      3       en  t_4054df11a74e         True   \n",
       "3            source      4       bg  t_e2452e21d252         True   \n",
       "4      supplemental      4       gu  t_0da7a331d666         True   \n",
       "...             ...    ...      ...             ...          ...   \n",
       "50091        source      4       pt  t_28dfc9e80110         True   \n",
       "50092        source      4       en  t_c75d6acecf78         True   \n",
       "50093  supplemental      2       es  t_5bd8f6ae9f7d         True   \n",
       "50094        source      4       sw  t_50145b9bab3f         True   \n",
       "50095       aligned      6       es  t_d448c707984d         True   \n",
       "\n",
       "                             parent_title         grandpa  \\\n",
       "0                      Открития и проекти  t_c85886762db7   \n",
       "1                        Álgebra: funções  t_461c9a8dd863   \n",
       "2          Flow Charts: Logical Thinking?  t_acbbd893e6af   \n",
       "3      Показателни и логаритмични функции  t_5f4cc8e02423   \n",
       "4           100 સુધીના સરવાળા અને બાદબાકી  t_d20fc01fdf38   \n",
       "...                                   ...             ...   \n",
       "50091      Álgebra: expressões algébricas  t_461c9a8dd863   \n",
       "50092                     Vector Analysis  t_de58fdbcad60   \n",
       "50093                     Lengua española  t_3eca90fe0fe1   \n",
       "50094                             Miduara  t_c520677cef1d   \n",
       "50095                            Unidad 4  t_8c734f803ed6   \n",
       "\n",
       "                     grandpa_title        ggrandpa  \\\n",
       "0                           Физика  t_27a0a3c7ee9a   \n",
       "1                           9º Ano  t_a6420bcff569   \n",
       "2                      Engineering  t_9c5f09334d83   \n",
       "3      Алгебра (цялото съдържание)  t_afd8db5e4f44   \n",
       "4                   પ્રારંભિક ગણિત  t_38bca5075c51   \n",
       "...                            ...             ...   \n",
       "50091                       9º Ano  t_a6420bcff569   \n",
       "50092                     Analysis  t_9d8388491acd   \n",
       "50093                 PF (Español)             NaN   \n",
       "50094              Class 9 (India)  t_4853606228df   \n",
       "50095      Español Actividades 1ro  t_7eb0dc459971   \n",
       "\n",
       "                             ggrandpa_title  fold  \\\n",
       "0                                     Наука     1   \n",
       "1      Matemática por ano (Alinhada à BNCC)     1   \n",
       "2                              MIT Blossoms     1   \n",
       "3                                Математика     1   \n",
       "4                                    ધોરણ ૩     1   \n",
       "...                                     ...   ...   \n",
       "50091  Matemática por ano (Alinhada à BNCC)     1   \n",
       "50092                                  Math     1   \n",
       "50093                                           1   \n",
       "50094                              Hisabati     1   \n",
       "50095                            01 Primero     1   \n",
       "\n",
       "                                                       t  sw  \\\n",
       "0      Откриването на резисторите @ Открития и проект...   1   \n",
       "1      Entradas e saídas de uma função @ Álgebra: fun...   1   \n",
       "2      Transcripts @ Flow Charts: Logical Thinking? @...   1   \n",
       "3      Графики на експоненциални функции (Алгебра 2 н...   1   \n",
       "4      100 સુધીનો સરવાળો @ 100 સુધીના સરવાળા અને બાદબ...   1   \n",
       "...                                                  ...  ..   \n",
       "50091  Fatoração de polinômios encontrando fatores co...   1   \n",
       "50092  Scalar Projections @ Vector Analysis @ Analysi...   1   \n",
       "50093  NA_U06 - El periódico @ Lengua española @ PF (...   1   \n",
       "50094  Inscribed shapes problem solving @ Miduara @ C...   1   \n",
       "50095  Lección 7 @ Unidad 4 @ Español Actividades 1ro...   1   \n",
       "\n",
       "                                                   label  \n",
       "0                       [111544, 113249, 114120, 114624]  \n",
       "1                           [89691, 35260, 35259, 89692]  \n",
       "2                                                [48571]  \n",
       "3               [111488, 116870, 111475, 116276, 116277]  \n",
       "4                               [126376, 126369, 126548]  \n",
       "...                                                  ...  \n",
       "50091         [47584, 47552, 34508, 34509, 34510, 47572]  \n",
       "50092                                     [91761, 91762]  \n",
       "50093  [22630, 41353, 82122, 63443, 41684, 62933, 640...  \n",
       "50094                                     [18867, 85597]  \n",
       "50095                                            [61581]  \n",
       "\n",
       "[50096 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corr_df[\"label\"] = le_topic.transform(corr_df[\"topic_id\"])\n",
    "corr_df = corr_df.merge(content_df[content_df[\"is_train\"]][[\"id\", \"label\"]].rename(columns={\"id\": \"content_ids\"}), on=\"content_ids\")\n",
    "\n",
    "\n",
    "content_labels = corr_df.groupby(\"topic_id\").agg({\"label\": list}).reset_index()\n",
    "content_labels = content_labels.rename(columns={\"topic_id\": \"id\"})\n",
    "content_labels[\"label\"] = content_labels[\"label\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "topic_df_train = topic_df_train.merge(content_labels, on=\"id\")\n",
    "\n",
    "topic_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3a040ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df[\"label\"] = content_df[\"label\"].apply(lambda x: [x])\n",
    "\n",
    "topic_df_test[\"label\"] = 0\n",
    "topic_df_test[\"label\"] = topic_df_test[\"label\"].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec897042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131987, 133656)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(le_topic.classes_), content_df[\"is_train\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2996f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90020221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 1024)\n",
      "    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (18): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (19): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (20): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (21): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (22): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (23): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "NW = 8\n",
    "BS = 64\n",
    "\n",
    "class LECRDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=512, aug=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.mask_token = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "        self.aug = aug\n",
    "        self.num_classes = len(le_topic.classes_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        encoding = self.tokenizer(str(row.t), return_offsets_mapping=True,\n",
    "                                  padding='max_length', truncation=True, max_length=self.max_len)\n",
    "\n",
    "        encoding = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "\n",
    "        if self.aug:\n",
    "            ix = torch.rand(size=(self.max_len,)) < 0.15\n",
    "            encoding[\"input_ids\"][ix] = self.mask_token\n",
    "            \n",
    "        target = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        for l in row.label:\n",
    "            target[l] = 1/len(row.label)\n",
    "        \n",
    "        return encoding, target, torch.FloatTensor([row.sw])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vec_model = VecModel(MODEL_NAME)\n",
    "model = TrainingModel(vec_model, num_classes=len(le_topic.classes_))\n",
    "model.model.load(\"models/vec_model_v29large.pth\")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba250761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def to_vec(model, ds):\n",
    "    val_loader = DataLoader(ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                             pin_memory=False, drop_last=False)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target, _) in enumerate(tbar):\n",
    "            ids, mask, target = data[\"input_ids\"].cuda(), data[\"attention_mask\"].cuda(), target.cuda()\n",
    "\n",
    "            vec = model.model(ids, mask)\n",
    "            vectors.append(vec.detach().cpu().numpy())\n",
    "\n",
    "    V = np.concatenate(vectors)\n",
    "    \n",
    "    return V\n",
    "\n",
    "\n",
    "\n",
    "def get_matches(V_topic, V_content, topic_ids, content_ids, n_neighbors=5):\n",
    "    \n",
    "    neighbors_model = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine', n_jobs=-1)\n",
    "    neighbors_model.fit(V_content)\n",
    "    dists, indices = neighbors_model.kneighbors(V_topic)\n",
    "    \n",
    "    res_df = pd.DataFrame({\"topic_id\": np.repeat(topic_ids, n_neighbors),\n",
    "                           'content_id': content_ids[indices.ravel()],\n",
    "                           'vec_dist': dists.ravel()\n",
    "                          })\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def f2(recall, precision):\n",
    "    return 5*precision*recall/(4*precision + recall)\n",
    "\n",
    "def metric(pred_df):\n",
    "    scores = np.zeros(pred_df.shape[0])\n",
    "\n",
    "    for i, (gt, pred) in enumerate(zip(pred_df[\"content_ids\"].values, pred_df[\"pred\"].values)):\n",
    "        hits = 0\n",
    "\n",
    "        gt, pred = gt.split(), pred.split()\n",
    "\n",
    "        for l in gt:\n",
    "            if l in pred:\n",
    "                hits += 1\n",
    "\n",
    "        if hits > 0:           \n",
    "            recall = hits / len(gt)\n",
    "            precision = hits / len(pred)\n",
    "\n",
    "            scores[i] = f2(recall, precision)\n",
    "\n",
    "    return scores.mean()\n",
    "    \n",
    "\n",
    "def evaluate(topic_df, content_df):    \n",
    "    topic_ds = LECRDataset(topic_df, tokenizer, MAX_LEN, aug=False)\n",
    "    content_ds = LECRDataset(content_df, tokenizer, MAX_LEN, aug=False)\n",
    "\n",
    "\n",
    "    V_topic = to_vec(model, topic_ds)\n",
    "    V_content = to_vec(model, content_ds)\n",
    "\n",
    "    res_df = get_matches(V_topic, V_content, topic_df[\"id\"].values, content_df[\"id\"].values)\n",
    "\n",
    "    res_df[\"rank\"] = res_df.groupby(\"topic_id\")[\"vec_dist\"].rank(method=\"first\", ascending=True)\n",
    "\n",
    "    pred_df = res_df.copy() #res_df[(res_df[\"rank\"] == 1) | (res_df[\"vec_dist\"] < 0.1)]\n",
    "    pred_df = pred_df.groupby(\"topic_id\")[\"content_id\"].apply(lambda x: \" \".join(list(x)))\n",
    "    pred_df = pred_df.reset_index().rename(columns={\"content_id\": 'pred'})\n",
    "    pred_df = pred_df.merge(pd.read_csv(\"data/correlations.csv\"), on=\"topic_id\")\n",
    "\n",
    "    return metric(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71338fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30885/362973530.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cls_df[\"ix\"] = le_topic.transform(cls_df[\"t\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2063/2063 [04:10<00:00,  8.25it/s]\n"
     ]
    }
   ],
   "source": [
    "cls_df = content_df[content_df[\"is_train\"]]\n",
    "cls_df[\"ix\"] = le_topic.transform(cls_df[\"t\"])\n",
    "cls_df = cls_df[[\"ix\", \"t\"]].drop_duplicates().sort_values(\"ix\").reset_index(drop=True)\n",
    "\n",
    "cls_df[\"label\"] = cls_df[\"ix\"].apply(lambda x: [x])\n",
    "cls_df[\"sw\"] = 1\n",
    "\n",
    "ds = LECRDataset(cls_df, tokenizer, MAX_LEN, aug=False)\n",
    "\n",
    "V_cls = to_vec(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2cd6d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingModel(\n",
       "  (model): VecModel(\n",
       "    (backbone): XLMRobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (18): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (19): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (20): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (21): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (22): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (23): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (top): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (arcface): ArcMarginProduct()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.arcface.arc_weight = nn.Parameter(torch.FloatTensor(V_cls))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ddb6091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30885/2716447418.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = topic_df_train.append(content_df[content_df[\"is_train\"]]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.7599 Acc: 0.37 lr: 4e-06: 100%|█| 2871/2871 [15:59<00:00,  2.99i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.19it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:34<00:00,  8.36it/s]\n",
      "Val score: 0.5077915870396498\n",
      "\n",
      "Epoch 2 Loss: 2.3525 Acc: 0.45 lr: 4e-06: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.18it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.31it/s]\n",
      "Val score: 0.507178813573554\n",
      "\n",
      "Epoch 3 Loss: 6.3543 Acc: 0.15 lr: 8e-05: 100%|█| 2871/2871 [15:56<00:00,  3.00i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.16it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5224243719429479\n",
      "\n",
      "Epoch 4 Loss: 3.763 Acc: 0.25 lr: 8e-05: 100%|█| 2871/2871 [15:57<00:00,  3.00it\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.17it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5229413725657169\n",
      "\n",
      "Epoch 5 Loss: 2.2929 Acc: 0.37 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.13it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5256102935145179\n",
      "\n",
      "Epoch 6 Loss: 1.6649 Acc: 0.47 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.16it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.524639664613709\n",
      "\n",
      "Epoch 7 Loss: 1.2984 Acc: 0.56 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.13it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:34<00:00,  8.33it/s]\n",
      "Val score: 0.5289407401736232\n",
      "\n",
      "Epoch 8 Loss: 1.1006 Acc: 0.61 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.12it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:34<00:00,  8.34it/s]\n",
      "Val score: 0.5313278683513906\n",
      "\n",
      "Epoch 9 Loss: 0.9601 Acc: 0.66 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:34<00:00,  8.34it/s]\n",
      "Val score: 0.5318750384547201\n",
      "\n",
      "Epoch 10 Loss: 0.8827 Acc: 0.69 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.13it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:34<00:00,  8.34it/s]\n",
      "Val score: 0.5353751666101461\n",
      "\n",
      "Epoch 11 Loss: 0.8373 Acc: 0.71 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.14it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.534524127548726\n",
      "\n",
      "Epoch 12 Loss: 0.808 Acc: 0.72 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.539970014052198\n",
      "\n",
      "Epoch 13 Loss: 0.7911 Acc: 0.72 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.16it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.31it/s]\n",
      "Val score: 0.5377036670466114\n",
      "\n",
      "Epoch 14 Loss: 0.7853 Acc: 0.72 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5408740975795943\n",
      "\n",
      "Epoch 15 Loss: 0.7851 Acc: 0.71 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.14it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5406620620178416\n",
      "\n",
      "Epoch 16 Loss: 0.7941 Acc: 0.7 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.540102856918456\n",
      "\n",
      "Epoch 17 Loss: 0.8071 Acc: 0.69 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5405051068695732\n",
      "\n",
      "Epoch 18 Loss: 0.8272 Acc: 0.67 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5431844575687322\n",
      "\n",
      "Epoch 19 Loss: 0.8562 Acc: 0.65 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.14it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5429757951592654\n",
      "\n",
      "Epoch 20 Loss: 0.8945 Acc: 0.62 lr: 8e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.16it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.32it/s]\n",
      "Val score: 0.5453242301775839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(pred, soft_targets, sw):\n",
    "    logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    return torch.mean(torch.sum(- soft_targets * logsoftmax(pred), 1)*sw)\n",
    "\n",
    "\n",
    "def train(model, epochs=2, n_batches=1, dynamic_margin=True):\n",
    "    train_df = topic_df_train.append(content_df[content_df[\"is_train\"]]).reset_index(drop=True)\n",
    "    train_ds = LECRDataset(train_df, tokenizer, MAX_LEN, aug=False)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n",
    "                               pin_memory=False, drop_last=True)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        if dynamic_margin:\n",
    "            model.arcface.set_margin(0.1 + e*0.02)\n",
    "        model.cuda()\n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "\n",
    "        lr = adjust_lr(optimizer, e)\n",
    "\n",
    "        loss_list, acc_list = [], []\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for idx, (data, label, sw) in enumerate(tbar):\n",
    "            ids, mask, label = data[\"input_ids\"].cuda(), data[\"attention_mask\"].cuda(), label.cuda()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                preds = model(ids, mask, label)\n",
    "                loss = cross_entropy(preds, label, sw.cuda())\n",
    "\n",
    "            loss = loss / n_batches\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if ((idx + 1) % n_batches) == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            acc = (preds.softmax(dim=1)*(label > 0)).sum(axis=1).mean()\n",
    "\n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            acc_list.append(acc.detach().cpu().item())\n",
    "            avg_loss = np.round(n_batches * np.mean(loss_list), 4)\n",
    "            avg_acc = np.round(np.mean(acc_list), 2)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} Acc: {avg_acc} lr: {lr}\")\n",
    "\n",
    "        torch.save(model.state_dict(), \"models/tmp.pth\")\n",
    "        log_text = f\"Epoch {e+1}\\n\"\n",
    "        logfile = open(f\"logs/log.txt\", 'a')\n",
    "        logfile.write(log_text)\n",
    "        logfile.close()\n",
    "        \n",
    "        val_score = evaluate(topic_df_test, content_df)\n",
    "        print(\"Val score:\", val_score)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "torch.save(model.state_dict(), \"models/tmp.pth\")\n",
    "log_text = f\"Epoch 0\\n\"\n",
    "logfile = open(f\"logs/log.txt\", 'a')\n",
    "logfile.write(log_text)\n",
    "logfile.close()\n",
    "\n",
    "train(model, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98dc7ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30885/2716447418.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = topic_df_train.append(content_df[content_df[\"is_train\"]]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7792 Acc: 0.68 lr: 2e-05: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.15it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5476839401377978\n",
      "\n",
      "Epoch 2 Loss: 0.6089 Acc: 0.78 lr: 8e-06: 100%|█| 2871/2871 [15:54<00:00,  3.01i\n",
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.13it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:35<00:00,  8.33it/s]\n",
      "Val score: 0.5472779960925194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch >= 1:\n",
    "        lr = 8e-6\n",
    "    else:\n",
    "        lr = 2e-5\n",
    "\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    optimizer.param_groups[1]['lr'] = 100*lr     \n",
    "    \n",
    "    return lr\n",
    "\n",
    "model.arcface.set_margin(0.5)\n",
    "train(model, epochs=2, dynamic_margin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b01ee5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save(\"models/vec_model_v35large.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "038fce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 129/129 [00:15<00:00,  8.17it/s]\n",
      "100%|███████████████████████████████████████| 2292/2292 [04:34<00:00,  8.34it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_ds = LECRDataset(topic_df_test, tokenizer, MAX_LEN, aug=False)\n",
    "content_ds = LECRDataset(content_df, tokenizer, MAX_LEN, aug=False)\n",
    "\n",
    "\n",
    "V_topic = to_vec(model, topic_ds)\n",
    "V_content = to_vec(model, content_ds)\n",
    "\n",
    "res_df = get_matches(V_topic, V_content, topic_df_test[\"id\"].values, content_df[\"id\"].values,\n",
    "                    n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c3788f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8641123925725633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_case_metric(pred_df):\n",
    "    scores = np.zeros(pred_df.shape[0])\n",
    "\n",
    "    for i, (gt, pred) in enumerate(zip(pred_df[\"content_ids\"].values, pred_df[\"pred\"].values)):\n",
    "        hits = 0\n",
    "\n",
    "        gt, pred = gt.split(), pred.split()\n",
    "\n",
    "        for l in gt:\n",
    "            if l in pred:\n",
    "                hits += 1\n",
    "\n",
    "        if hits > 0:           \n",
    "            recall = hits / len(gt)\n",
    "            precision = 1 #hits / len(pred)\n",
    "\n",
    "            scores[i] = f2(recall, precision)\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "pred_df = res_df.groupby(\"topic_id\")[\"content_id\"].apply(lambda x: \" \".join(list(x)))\n",
    "pred_df = pred_df.reset_index().rename(columns={\"content_id\": 'pred'})\n",
    "pred_df = pred_df.merge(pd.read_csv(\"data/correlations.csv\"), on=\"topic_id\")\n",
    "\n",
    "best_case_metric(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b317fe32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5368375813055577"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[\"rank\"] = res_df.groupby(\"topic_id\")[\"vec_dist\"].rank(method=\"dense\")\n",
    "\n",
    "\n",
    "pred_df = res_df[(res_df[\"rank\"] <= 2) | (res_df[\"vec_dist\"] < 0.3)]\n",
    "pred_df = pred_df.groupby(\"topic_id\")[\"content_id\"].apply(lambda x: \" \".join(list(x)))\n",
    "pred_df = pred_df.reset_index().rename(columns={\"content_id\": 'pred'})\n",
    "pred_df = pred_df.merge(pd.read_csv(\"data/correlations.csv\"), on=\"topic_id\")\n",
    "\n",
    "metric(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "655829d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_df[\"vec_dist\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdbd4bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>vec_dist</th>\n",
       "      <th>rank</th>\n",
       "      <th>id_x</th>\n",
       "      <th>language_x</th>\n",
       "      <th>id_y</th>\n",
       "      <th>language_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>c_b8d730238789</td>\n",
       "      <td>0.335340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c_b8d730238789</td>\n",
       "      <td>en</td>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>c_1ec97b588bce</td>\n",
       "      <td>0.370095</td>\n",
       "      <td>2.0</td>\n",
       "      <td>c_1ec97b588bce</td>\n",
       "      <td>en</td>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>c_7868f655c31e</td>\n",
       "      <td>0.377190</td>\n",
       "      <td>3.0</td>\n",
       "      <td>c_7868f655c31e</td>\n",
       "      <td>en</td>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>c_7cc189e7acb0</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>c_7cc189e7acb0</td>\n",
       "      <td>en</td>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>c_d7b213393f30</td>\n",
       "      <td>0.414671</td>\n",
       "      <td>5.0</td>\n",
       "      <td>c_d7b213393f30</td>\n",
       "      <td>en</td>\n",
       "      <td>t_000d1fb3f2f5</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164955</th>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>c_57d3a5def774</td>\n",
       "      <td>0.548574</td>\n",
       "      <td>16.0</td>\n",
       "      <td>c_57d3a5def774</td>\n",
       "      <td>en</td>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164956</th>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>c_6d8181bdea2c</td>\n",
       "      <td>0.549629</td>\n",
       "      <td>17.0</td>\n",
       "      <td>c_6d8181bdea2c</td>\n",
       "      <td>en</td>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164957</th>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>c_4fe6f29d8fce</td>\n",
       "      <td>0.552202</td>\n",
       "      <td>18.0</td>\n",
       "      <td>c_4fe6f29d8fce</td>\n",
       "      <td>en</td>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164958</th>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>c_79478f242be4</td>\n",
       "      <td>0.560271</td>\n",
       "      <td>19.0</td>\n",
       "      <td>c_79478f242be4</td>\n",
       "      <td>en</td>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164959</th>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>c_ef9484b60490</td>\n",
       "      <td>0.565709</td>\n",
       "      <td>20.0</td>\n",
       "      <td>c_ef9484b60490</td>\n",
       "      <td>en</td>\n",
       "      <td>t_eb4bc22f86da</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164960 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              topic_id      content_id  vec_dist  rank            id_x  \\\n",
       "0       t_000d1fb3f2f5  c_b8d730238789  0.335340   1.0  c_b8d730238789   \n",
       "1       t_000d1fb3f2f5  c_1ec97b588bce  0.370095   2.0  c_1ec97b588bce   \n",
       "2       t_000d1fb3f2f5  c_7868f655c31e  0.377190   3.0  c_7868f655c31e   \n",
       "3       t_000d1fb3f2f5  c_7cc189e7acb0  0.378100   4.0  c_7cc189e7acb0   \n",
       "4       t_000d1fb3f2f5  c_d7b213393f30  0.414671   5.0  c_d7b213393f30   \n",
       "...                ...             ...       ...   ...             ...   \n",
       "164955  t_eb4bc22f86da  c_57d3a5def774  0.548574  16.0  c_57d3a5def774   \n",
       "164956  t_eb4bc22f86da  c_6d8181bdea2c  0.549629  17.0  c_6d8181bdea2c   \n",
       "164957  t_eb4bc22f86da  c_4fe6f29d8fce  0.552202  18.0  c_4fe6f29d8fce   \n",
       "164958  t_eb4bc22f86da  c_79478f242be4  0.560271  19.0  c_79478f242be4   \n",
       "164959  t_eb4bc22f86da  c_ef9484b60490  0.565709  20.0  c_ef9484b60490   \n",
       "\n",
       "       language_x            id_y language_y  \n",
       "0              en  t_000d1fb3f2f5         en  \n",
       "1              en  t_000d1fb3f2f5         en  \n",
       "2              en  t_000d1fb3f2f5         en  \n",
       "3              en  t_000d1fb3f2f5         en  \n",
       "4              en  t_000d1fb3f2f5         en  \n",
       "...           ...             ...        ...  \n",
       "164955         en  t_eb4bc22f86da         en  \n",
       "164956         en  t_eb4bc22f86da         en  \n",
       "164957         en  t_eb4bc22f86da         en  \n",
       "164958         en  t_eb4bc22f86da         en  \n",
       "164959         en  t_eb4bc22f86da         en  \n",
       "\n",
       "[164960 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = res_df.merge(content_df[[\"id\", \"language\"]], left_on=\"content_id\", right_on=\"id\")\n",
    "x = x.merge(topic_df[[\"id\", \"language\"]], left_on=\"topic_id\", right_on=\"id\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "420793e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9420404946653734, 0.9697438985918725)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"same_lang\"] = x[\"language_x\"] == x[\"language_y\"]\n",
    "x[\"same_lang\"].mean(), x[x[\"vec_dist\"] < 0.5][\"same_lang\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c7c086e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6350166819335277"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = x[(x[\"rank\"] <= 1) | (x[\"same_lang\"] & (x[\"vec_dist\"] < 0.45))]\n",
    "pred_df = pred_df.groupby(\"topic_id\")[\"content_id\"].apply(lambda x: \" \".join(list(x)))\n",
    "pred_df = pred_df.reset_index().rename(columns={\"content_id\": 'pred'})\n",
    "pred_df = pred_df.merge(pd.read_csv(\"data/correlations.csv\"), on=\"topic_id\")\n",
    "\n",
    "metric(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b36b3f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076739340019989"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = get_matches(V_topic, V_content, topic_df_test[\"id\"].values, content_df[\"id\"].values,\n",
    "                    n_neighbors=50)\n",
    "\n",
    "pred_df = res_df.groupby(\"topic_id\")[\"content_id\"].apply(lambda x: \" \".join(list(x)))\n",
    "pred_df = pred_df.reset_index().rename(columns={\"content_id\": 'pred'})\n",
    "pred_df = pred_df.merge(pd.read_csv(\"data/correlations.csv\"), on=\"topic_id\")\n",
    "\n",
    "best_case_metric(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c1b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
